# -*- coding: utf-8 -*-
from __future__ import annotations

import unicodedata
from pathlib import Path
from datetime import datetime
from io import StringIO

import pandas as pd
import numpy as np
import altair as alt

try:
    import streamlit as st
except Exception as e:
    raise RuntimeError("Streamlit import ì‹¤íŒ¨. requirements.txtì— streamlitì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.") from e


# =========================================================
# ì¸ì½”ë”© ìë™ ê°ì§€í˜• CSV ë¡œë”
# =========================================================
def read_csv_kr(path):
    """
    cp949 ì‹¤íŒ¨ ì‹œ utf-8-sig â†’ utf-8 â†’ cp1252 â†’ latin-1 ìˆœìœ¼ë¡œ ì¬ì‹œë„.
    ê·¸ë˜ë„ ì‹¤íŒ¨í•˜ë©´ 'ignore'ë¡œ ê¹¨ì§€ëŠ” ë¬¸ì ë¬´ì‹œí•˜ê³  ë¡œë“œ.
    df.attrs['encoding_used']ì— ì‚¬ìš©ëœ ì¸ì½”ë”© ê¸°ë¡.
    """
    enc_candidates = ["cp949", "utf-8-sig", "utf-8", "cp1252", "latin-1"]
    last_err = None
    for enc in enc_candidates:
        try:
            df = pd.read_csv(path, encoding=enc)
            df.attrs["encoding_used"] = enc
            return df
        except Exception as e:
            last_err = e
            continue
    # ìµœí›„ ìˆ˜ë‹¨: ê¹¨ì§ ë¬´ì‹œ
    with open(path, "rb") as f:
        raw = f.read()
    txt = raw.decode("utf-8", errors="ignore")
    df = pd.read_csv(StringIO(txt))
    df.attrs["encoding_used"] = "utf-8(ignore)"
    return df


# =========================================================
# ê²¬ê³ í•œ íŒŒì¼ íƒìƒ‰ê¸° (ë§¥/ë¦¬ëˆ…ìŠ¤ í•œê¸€ ì •ê·œí™” ì°¨ì´ ëŒ€ì‘)
# =========================================================
def resolve_file(preferred_name: str, patterns: list[str]) -> Path:
    """
    preferred_name: ê¸°ëŒ€ íŒŒì¼ëª…(ì •í™• ì¼ì¹˜ ìš°ì„ )
    patterns: ëŒ€ì²´ ê¸€ë¡­ íŒ¨í„´
    """
    base = Path(__file__).parent.resolve()

    # ì •í™• ì¼ì¹˜ (NFC ì •ê·œí™”)
    pref_nfc = unicodedata.normalize("NFC", preferred_name)
    p = base / pref_nfc
    if p.exists():
        return p

    # ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ëª… ì •ê·œí™” ë¹„êµ
    for child in base.iterdir():
        if child.is_file():
            name_nfc = unicodedata.normalize("NFC", child.name)
            if name_nfc == pref_nfc:
                return child

    # íŒ¨í„´ ê²€ìƒ‰
    for pat in patterns:
        for hit in base.glob(pat):
            return hit

    # ì‹¤íŒ¨ ì‹œ ë””ë ‰í† ë¦¬ ëª©ë¡ ì¶œë ¥
    all_files = [unicodedata.normalize("NFC", c.name) for c in base.iterdir() if c.is_file()]
    raise FileNotFoundError(
        f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{preferred_name}'\n"
        f"ê²€ìƒ‰ í´ë”: {base}\n"
        f"íŒ¨í„´: {patterns}\n"
        f"í˜„ì¬ í´ë” íŒŒì¼: {all_files}"
    )


# =========================================================
# íŒŒì¼ ê²½ë¡œ ê²°ì • (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ íŒŒì¼ëª… ë°”ë€Œì–´ë„ ì‘ë™)
# =========================================================
ENV_FILE = resolve_file(
    "ì†¡ë„ê³  í™˜ê²½ë°ì´í„° í†µí•©.csv",
    patterns=["*í™˜ê²½*í†µí•©*.csv", "*í™˜ê²½ë°ì´í„°*í†µí•©*.csv", "*í™˜ê²½ë°ì´í„°*.csv"]
)
GROW_FILE = resolve_file(
    "ì†¡ë„ê³  ìŠ¤ë§ˆíŠ¸íŒœ ìƒìœ¡ ê²°ê³¼.csv",
    patterns=["*ìŠ¤ë§ˆíŠ¸íŒœ*ìƒìœ¡*ê²°ê³¼*.csv", "*ìƒìœ¡*ê²°ê³¼*.csv", "*ìŠ¤ë§ˆíŠ¸íŒœ*.csv"]
)


UNITS = {
    "temp": "â„ƒ", "humid": "%", "co2": "ppm", "ec": "dS/m", "ph": "", "wt": "â„ƒ",
    "length": "cm", "wet_weight": "g", "dry_weight": "g"
}


# =========================================================
# ê³µí†µ ìœ í‹¸
# =========================================================
def fmt_num(x):
    return "-" if pd.isna(x) else f"{x:,.2f}"

def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    mapping = {
        "ì¸¡ì •ì¼ì‹œ":"date","ì¼ì‹œ":"date","ë‚ ì§œ":"date","date":"date",
        "ì˜¨ë„(â„ƒ)":"temp","ì˜¨ë„":"temp","temp":"temp","tmep":"temp",
        "ìŠµë„(%)":"humid","ìŠµë„":"humid","humidity":"humid","humid":"humid",
        "coâ‚‚(ppm)":"co2","co2(ppm)":"co2","co2":"co2","coâ‚‚":"co2",
        "ec(ds/m)":"ec","ec":"ec","pH":"ph","ph":"ph",
        "ìˆ˜ì˜¨(â„ƒ)":"wt","ìˆ˜ì˜¨":"wt","w.t":"wt","water_temp":"wt","wt":"wt",
        "ì§€ìƒë¶€ ê¸¸ì´(cm)":"length","ìƒìœ¡ê¸¸ì´(cm)":"length","ê¸¸ì´(cm)":"length","length":"length",
        "ì ìˆ˜(ì¥)":"leaves","ììˆ˜(ê°œ)":"leaves","leaves":"leaves",
        "ì§€ìƒë¶€ ìƒì¤‘ëŸ‰(g)":"wet_weight","ìƒì¤‘ëŸ‰(g)":"wet_weight","wet_weight":"wet_weight",
        "ì§€ìƒë¶€ ê±´ì¤‘ëŸ‰(g)":"dry_weight","ê±´ì¤‘ëŸ‰(g)":"dry_weight","dry_weight":"dry_weight",
    }
    new_cols = []
    for c in df.columns:
        key = c.strip()
        low = key.lower()
        if key in mapping: new_cols.append(mapping[key]); continue
        if low in mapping: new_cols.append(mapping[low]); continue
        if any(k in low for k in ["ì˜¨ë„","temp","tmep"]): new_cols.append("temp")
        elif any(k in low for k in ["ìŠµë„","humid"]): new_cols.append("humid")
        elif "co2" in low or "coâ‚‚" in key.lower(): new_cols.append("co2")
        elif low.startswith("ec"): new_cols.append("ec")
        elif low == "ph": new_cols.append("ph")
        elif any(k in low for k in ["ìˆ˜ì˜¨","water","w.t","wt"]): new_cols.append("wt")
        elif any(k in low for k in ["ììˆ˜","ì ìˆ˜","leaves"]): new_cols.append("leaves")
        elif any(k in low for k in ["ìƒìœ¡ê¸¸ì´","ì§€ìƒë¶€ ê¸¸ì´","length"]): new_cols.append("length")
        elif any(k in low for k in ["ìƒì¤‘ëŸ‰","wet_weight"]): new_cols.append("wet_weight")
        elif any(k in low for k in ["ê±´ì¤‘ëŸ‰","dry_weight"]): new_cols.append("dry_weight")
        elif any(k in low for k in ["ì¸¡ì •ì¼ì‹œ","ì¼ì‹œ","ë‚ ì§œ","date"]): new_cols.append("date")
        else: new_cols.append(c)
    df.columns = new_cols
    return df

def numeric_summary(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:
    if not cols:
        return pd.DataFrame({"column":[], "mean":[], "min":[], "max":[]})
    out = df[cols].agg(["mean","min","max"]).T.reset_index()
    out.columns = ["column","mean","min","max"]
    return out


# =========================================================
# ë°ì´í„° ë¡œë”
# =========================================================
def parse_env_csv(path: str) -> pd.DataFrame:
    """
    í™˜ê²½ CSV ì „ìš© íŒŒì„œ: ë³€ìˆ˜ë³„ ì„œë¡œ ë‹¤ë¥¸ ë‚ ì§œ/ì‹œê°„ ì—´ì„ ë‹¨ì¼ dateë¡œ ê²°í•©.
    """
    raw = read_csv_kr(path)  # â† ì¸ì½”ë”© ìë™ ì²˜ë¦¬
    # ì˜ˆìƒ ì—´ ì˜ˆ: ['ë‚ ì§œ','ì‹œê°„','co2','ë‚ ì§œ.1','ì‹œê°„.1','ec','ph','w.t','ë‚ ì§œ.2','ì‹œê°„.2','humid','ë‚ ì§œ.3','ì‹œê°„.3','temp']
    var_map = {
        "co2":   ("ë‚ ì§œ","ì‹œê°„","co2"),
        "ec":    ("ë‚ ì§œ.1","ì‹œê°„.1","ec"),
        "ph":    ("ë‚ ì§œ.1","ì‹œê°„.1","ph"),
        "wt":    ("ë‚ ì§œ.1","ì‹œê°„.1","w.t"),
        "humid": ("ë‚ ì§œ.2","ì‹œê°„.2","humid"),
        "temp":  ("ë‚ ì§œ.3","ì‹œê°„.3","temp"),
    }
    frames = []
    for var, (dc, tc, vc) in var_map.items():
        if dc in raw.columns and tc in raw.columns and vc in raw.columns:
            df = raw[[dc, tc, vc]].copy()
            df["date"] = pd.to_datetime(
                df[dc].astype(str).str.strip() + " " + df[tc].astype(str).str.strip(),
                errors="coerce"
            )
            df = df.drop(columns=[dc, tc]).rename(columns={vc: var})
            df = df[~df["date"].isna()]
            frames.append(df.set_index("date"))

    if not frames:
        raw = standardize_columns(raw)
        if "date" not in raw.columns:
            raw["date"] = pd.to_datetime(raw.iloc[:,0], errors="coerce")
        return raw

    env = pd.concat(frames, axis=1).sort_index().reset_index()
    return env


def load_growth_csv(path: str) -> pd.DataFrame:
    # 1) ì¸ì½”ë”© ìë™ ì²˜ë¦¬ë¡œ ì½ê¸°
    df = read_csv_kr(path)

    # 2) ëª¨ë“  ì»¬ëŸ¼ëª…ì„ ë¬¸ìì—´ë¡œ í†µì¼ (ìˆ«ì/None ëŒ€ë¹„)
    df.columns = [str(c).strip() for c in df.columns.tolist()]

    # 3) ì—‘ì…€â†’CSV ë³€í™˜ ì‹œ ìƒê¸°ëŠ” 'Unnamed' ê³„ì—´ ì»¬ëŸ¼ ì œê±° (ì‹¤íŒ¨í•´ë„ ì•ˆì „)
    try:
        df = df.loc[:, ~pd.Index(df.columns).str.contains(r"^Unnamed", regex=True)]
    except Exception:
        # í˜¹ì‹œë¼ë„ str.containsê°€ ë˜ ë§‰íˆë©´ ìˆ˜ë™ í•„í„°ë¡œ ëŒ€ì²´
        df = df[[c for c in df.columns if not str(c).startswith("Unnamed")]]

    # 4) í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ í†µì¼
    df = standardize_columns(df)

    # 5) ìˆ«ìí˜• ë³€í™˜
    for c in ["length", "leaves", "wet_weight", "dry_weight"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # (ì„ íƒ) date ì»¬ëŸ¼ì´ ë¬¸ìì—´/ìˆ«ìì—¬ë„ ë‚ ì§œë¡œ ë³€í™˜ ì‹œë„
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

    return df



# =========================================================
# ìƒê´€/ì‹œê°í™”
# =========================================================
def corr_env_vs_growth(env_df: pd.DataFrame, grow_df: pd.DataFrame, env_cols, grow_cols):
    if "date" in env_df.columns and "date" in grow_df.columns:
        merged = pd.merge(env_df[["date"]+env_cols], grow_df[["date"]+grow_cols], on="date", how="inner")
    else:
        return pd.DataFrame(columns=["env","grow","corr"])
    pairs = []
    for e in env_cols:
        for g in grow_cols:
            s = merged[[e,g]].dropna()
            if len(s) >= 3:
                pairs.append({"env":e,"grow":g,"corr":s[e].corr(s[g])})
    return pd.DataFrame(pairs)

def altair_heatmap(corr_df: pd.DataFrame):
    if corr_df.empty:
        return alt.Chart(pd.DataFrame({"msg":["ìƒê´€ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]})).mark_text().encode(text="msg")
    corr_df = corr_df.copy()
    corr_df["corr_label"] = corr_df["corr"].round(2).astype(str)
    base = alt.Chart(corr_df).mark_rect().encode(
        x=alt.X("env:N", title="í™˜ê²½ ë³€ìˆ˜"),
        y=alt.Y("grow:N", title="ìƒìœ¡ ì§€í‘œ"),
        color=alt.Color("corr:Q", scale=alt.Scale(scheme="redblue", domain=(-1,1))),
        tooltip=[alt.Tooltip("env:N"), alt.Tooltip("grow:N"), alt.Tooltip("corr:Q", format=".3f")]
    ).properties(title="í™˜ê²½â€“ìƒìœ¡ ìƒê´€ê³„ìˆ˜ Heatmap", height=300)
    text = alt.Chart(corr_df).mark_text(baseline="middle").encode(
        x="env:N", y="grow:N", text="corr_label:N"
    )
    return base + text

def scatter_grid(df, env_cols, grow_cols):
    charts = []
    for e in env_cols:
        for g in grow_cols:
            s = df[[e,g]].dropna()
            if len(s) < 3: 
                continue
            c = alt.Chart(s).mark_circle(opacity=0.5).encode(
                x=alt.X(f"{e}:Q", title=f"{e} ({UNITS.get(e,'')})"),
                y=alt.Y(f"{g}:Q", title=f"{g} ({UNITS.get(g,'')})"),
                tooltip=[alt.Tooltip(f"{e}:Q", format=",.2f"), alt.Tooltip(f"{g}:Q", format=",.2f")]
            ).properties(width=300, height=240)
            charts.append(c + c.transform_regression(e, g).mark_line())
    if not charts:
        return alt.Chart(pd.DataFrame({"msg":["í‘œì‹œí•  ì‚°ì ë„ê°€ ì—†ìŠµë‹ˆë‹¤."]})).mark_text().encode(text="msg")
    row = None; rows = []
    for i, ch in enumerate(charts):
        row = ch if i % 3 == 0 else row | ch
        if i % 3 == 2: rows.append(row)
    if row is not None and (len(charts) % 3 != 0): rows.append(row)
    out = rows[0]
    for r in rows[1:]: out = out & r
    return out.properties(title="í™˜ê²½ìš”ì†Œë³„ ìƒìœ¡ ì˜í–¥ë„")


# =========================================================
# Streamlit UI
# =========================================================
st.set_page_config(page_title="ì†¡ë„ê³  EcoSmartFarm ëŒ€ì‹œë³´ë“œ", page_icon="ğŸŒ¿", layout="wide")
st.title("ğŸŒ¿ ì†¡ë„ê³  EcoSmartFarm í™˜ê²½Â·ìƒìœ¡ ë°ì´í„° ëŒ€ì‹œë³´ë“œ")

with st.expander("ğŸ“¥ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ìš”ì•½", expanded=True):
    # í™˜ê²½ ë°ì´í„°
    try:
        env_df = parse_env_csv(ENV_FILE)
        st.success(f"í™˜ê²½ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {ENV_FILE} (shape={env_df.shape})")
        st.caption(f"í™˜ê²½ CSV ì¸ì½”ë”©: {getattr(env_df, 'attrs', {}).get('encoding_used', 'unknown')}")
    except Exception as e:
        st.error(f"í™˜ê²½ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        st.stop()

    # ìƒìœ¡ ë°ì´í„°
    try:
        grow_df = load_growth_csv(GROW_FILE)
        st.success(f"ìƒìœ¡ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {GROW_FILE} (shape={grow_df.shape})")
        st.caption(f"ìƒìœ¡ CSV ì¸ì½”ë”©: {getattr(grow_df, 'attrs', {}).get('encoding_used', 'unknown')}")
    except Exception as e:
        st.warning(f"ìƒìœ¡ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨(ì„ íƒì‚¬í•­): {e}")
        grow_df = pd.DataFrame()

    # í‘œì¤€í™” & ë‚ ì§œ ë³€í™˜
    env_df = standardize_columns(env_df)
    if "date" in env_df.columns:
        env_df["date"] = pd.to_datetime(env_df["date"], errors="coerce")

    st.subheader("í™˜ê²½ ë°ì´í„° ì²˜ìŒ 10í–‰")
    st.dataframe(env_df.head(10), use_container_width=True)

    if not grow_df.empty:
        st.subheader("ìƒìœ¡ ë°ì´í„° ì²˜ìŒ 10í–‰")
        st.dataframe(grow_df.head(10), use_container_width=True)

    # íƒ€ì…/ê²°ì¸¡ ë³´ê³ 
    def report(df: pd.DataFrame):
        rows = []
        for c in df.columns:
            miss = df[c].isna().mean()*100 if len(df) else 0
            can_num = df[c].dtype.kind in "biufc"
            if not can_num:
                try:
                    pd.to_numeric(df[c], errors="raise"); can_num = True
                except Exception:
                    pass
            rows.append({"column":c, "dtype":str(df[c].dtype), "missing_ratio(%)":round(miss,2), "numeric_candidate":can_num})
        return pd.DataFrame(rows)

    st.subheader("í™˜ê²½ ë°ì´í„° íƒ€ì… & ê²°ì¸¡ ë¹„ìœ¨")
    st.dataframe(report(env_df), use_container_width=True)

    if not grow_df.empty:
        st.subheader("ìƒìœ¡ ë°ì´í„° íƒ€ì… & ê²°ì¸¡ ë¹„ìœ¨")
        st.dataframe(report(grow_df), use_container_width=True)

    st.subheader("ìˆ«ìí˜• ìš”ì•½ (í‰ê· /ìµœì†Ÿê°’/ìµœëŒ“ê°’)")
    env_num = [c for c in ["temp","humid","co2","ec","ph","wt"] if c in env_df.columns]
    st.write("í™˜ê²½:", numeric_summary(env_df, env_num))

    if not grow_df.empty:
        grow_num = [c for c in ["length","wet_weight","dry_weight","leaves"] if c in grow_df.columns]
        st.write("ìƒìœ¡:", numeric_summary(grow_df, grow_num))


# ------------------- ì‚¬ì´ë“œë°” í•„í„° -------------------
st.sidebar.header("ğŸ” ë°ì´í„° í•„í„°")
if "date" in env_df.columns and env_df["date"].notna().any():
    min_date = env_df["date"].min()
    max_date = env_df["date"].max()
    start, end = st.sidebar.date_input(
        "ë‚ ì§œ ë²”ìœ„ ì„ íƒ (í™˜ê²½ ë°ì´í„° ê¸°ì¤€)",
        (min_date.date(), max_date.date()) if pd.notna(min_date) else (datetime.today().date(), datetime.today().date())
    )
    mask = (env_df["date"] >= pd.to_datetime(start)) & \
           (env_df["date"] <= pd.to_datetime(end) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1))
    env_f = env_df.loc[mask].copy()
else:
    st.sidebar.info("í™˜ê²½ ë°ì´í„°ì— dateê°€ ì—†ì–´ ì „ì²´ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    env_f = env_df.copy()

# ë‹¤ìš´ë¡œë“œ (cp949)
csv_bytes = env_f.to_csv(index=False, encoding="cp949").encode("cp949", errors="ignore")
st.sidebar.download_button("â¬‡ï¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV, cp949)", data=csv_bytes, file_name="filtered_env.csv", mime="text/csv")
st.sidebar.markdown("---")
st.sidebar.caption("**ë°ì´í„° ì¶œì²˜:** ì†¡ë„ê³ ë“±í•™êµ ìŠ¤ë§ˆíŠ¸íŒœ í”„ë¡œì íŠ¸(2025, ê·¹ì§€ì—°êµ¬ì†Œ Ã— ì¸ì²œêµìœ¡ì²­)")


# ------------------- ë©”íŠ¸ë¦­ -------------------
st.markdown("### ğŸ“Œ í•µì‹¬ ë©”íŠ¸ë¦­")
def avg(col, df):
    return pd.to_numeric(df[col], errors="coerce").mean() if col in df.columns else np.nan

m1,m2,m3,m4 = st.columns(4)
m1.metric("í‰ê·  ì˜¨ë„ (â„ƒ)", fmt_num(avg("temp", env_f)))
m2.metric("í‰ê·  ìŠµë„ (%)", fmt_num(avg("humid", env_f)))
m3.metric("í‰ê·  COâ‚‚ (ppm)", fmt_num(avg("co2", env_f)))
m4.metric("í‰ê·  EC (dS/m)", fmt_num(avg("ec", env_f)))
m5,m6,m7,_ = st.columns(4)
m5.metric("í‰ê·  pH", fmt_num(avg("ph", env_f)))
m6.metric("í‰ê·  ìƒìœ¡ê¸¸ì´ (cm)", fmt_num(avg("length", grow_df) if not grow_df.empty else np.nan))
m7.metric("í‰ê·  ìƒì¤‘ëŸ‰ (g)", fmt_num(avg("wet_weight", grow_df) if not grow_df.empty else np.nan))


# ------------------- ìƒê´€ & ì‹œê°í™” -------------------
st.markdown("### ğŸ”— í™˜ê²½â€“ìƒìœ¡ ìƒê´€ ë¶„ì„")
env_cols_sel = [c for c in ["temp","humid","co2","ec","ph","wt"] if c in env_f.columns]
grow_cols_sel = [c for c in ["length","wet_weight","dry_weight"] if not grow_df.empty and c in grow_df.columns]

corr_df = corr_env_vs_growth(env_f, grow_df, env_cols_sel, grow_cols_sel) if grow_cols_sel else pd.DataFrame(columns=["env","grow","corr"])

c1, c2 = st.columns([2,1])
with c1:
    st.altair_chart(altair_heatmap(corr_df), use_container_width=True)
with c2:
    if corr_df.empty:
        st.info("ìƒìœ¡ ë°ì´í„°ì— ë‚ ì§œ ì •ë³´ê°€ ì—†ê±°ë‚˜ ë§¤ì¹­ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ìƒê´€ ë¶„ì„ì„ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        top5 = corr_df.assign(abs_corr=corr_df["corr"].abs()).sort_values("abs_corr", ascending=False).head(5)
        st.markdown("**ìƒê´€ ìƒìœ„ 5ê°œ (ì ˆëŒ€ê°’ ê¸°ì¤€)**")
        st.dataframe(top5[["env","grow","corr"]].round(3), use_container_width=True)

st.markdown("### ğŸ“ˆ í™˜ê²½ìš”ì†Œë³„ ìƒìœ¡ ì˜í–¥ë„")
if not corr_df.empty:
    merged_for_plot = pd.merge(
        env_f[["date"]+env_cols_sel], grow_df[["date"]+grow_cols_sel],
        on="date", how="inner"
    ).dropna()
    st.altair_chart(scatter_grid(merged_for_plot, env_cols_sel, grow_cols_sel), use_container_width=True)
else:
    st.info("ë‚ ì§œê°€ ë§¤ì¹­ë˜ëŠ” í™˜ê²½â€“ìƒìœ¡ ë°ì´í„°ê°€ ì—†ì–´ ì‚°ì ë„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

st.markdown("---")
st.caption("Made by ì†¡ë„ê³  EcoSmartFarm Team, with AI support")
