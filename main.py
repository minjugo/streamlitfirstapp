# main.py
# -*- coding: utf-8 -*-
"""
Streamlit ëŒ€ì‹œë³´ë“œ - ê·¹ì§€ì‹ë¬¼ 4ê°œêµ EC ì‹¤í—˜ (ì—…ë¡œë“œ ë²„ì „)
- í™˜ê²½ CSV 4ê°œ(ê° í•™êµë³„): timestamp, temperature, humid, ec, ph, co2
- ìƒìœ¡ ì—‘ì…€ 1ê°œ(4ì‹œíŠ¸: ì†¡ë„ê³ /í•˜ëŠ˜ê³ /ì•„ë¼ê³ /ë™ì‚°ê³ )
  * ì¹¼ëŸ¼: ê°œì²´ë²ˆí˜¸, ì ìˆ˜(ì¥), ì§€ìƒë¶€ ê¸¸ì´(cm), ì§€ìƒë¶€ ìƒì¤‘ëŸ‰(g), ì§€í•˜ë¶€ ìƒì¤‘ëŸ‰(g)
  * ì•„ë¼ê³ ë§Œ: ìƒì¤‘ëŸ‰(g) (ì§€ìƒ/ì§€í•˜ êµ¬ë¶„ ì—†ìŒ)
- EC ë§¤í•‘: ì†¡ë„=1, í•˜ëŠ˜=2, ì•„ë¼=4, ë™ì‚°=8
"""

import io
import math
import streamlit as st
import pandas as pd
import altair as alt

# --------------------------
# 0) í˜ì´ì§€ ì„¤ì •
# --------------------------
st.set_page_config(page_title="ê·¹ì§€ì‹ë¬¼ ì‹¤í—˜", layout="wide")
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì‹¤í—˜ ëŒ€ì‹œë³´ë“œ")
st.subheader("4ê°œêµ ê³µë™ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„")

alt.data_transformers.disable_max_rows()  # Altair í–‰ ì œí•œ í•´ì œ(êµìœ¡ìš©)

SCHOOL_KEYS = ["ì†¡ë„ê³ ", "í•˜ëŠ˜ê³ ", "ì•„ë¼ê³ ", "ë™ì‚°ê³ "]
EC_MAP = {"ì†¡ë„ê³ ": 1, "í•˜ëŠ˜ê³ ": 2, "ì•„ë¼ê³ ": 4, "ë™ì‚°ê³ ": 8}
COLOR_MAP = {"ì†¡ë„ê³ ":"#8bb8ff", "í•˜ëŠ˜ê³ ":"#88d4a9", "ì•„ë¼ê³ ":"#ffd66b", "ë™ì‚°ê³ ":"#ff9b9b"}  # íŒŒìŠ¤í…”

# --------------------------
# 1) ì—…ë¡œë“œ ìœ„ì ¯ & ë§¤í•‘ ë³´ì¡°
# --------------------------
with st.sidebar:
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    env_files = st.file_uploader("í™˜ê²½ CSV 4ê°œ ì—…ë¡œë“œ", type=["csv"], accept_multiple_files=True, help="ê° í•™êµë³„ 1ê°œì”© ì—…ë¡œë“œí•˜ì„¸ìš”.")
    growth_file = st.file_uploader("ìƒìœ¡ ê²°ê³¼ ì—‘ì…€(.xlsx)", type=["xlsx"], help="ì‹œíŠ¸ëª…: ì†¡ë„ê³ /í•˜ëŠ˜ê³ /ì•„ë¼ê³ /ë™ì‚°ê³ ")

def infer_school_from_name(name: str) -> str | None:
    """íŒŒì¼ëª…ì—ì„œ í•™êµëª…ì„ ì¶”ë¡ (ê°„ë‹¨ í‚¤ì›Œë“œ ë§¤ì¹­)"""
    key = name.lower()
    if "ì†¡ë„" in key: return "ì†¡ë„ê³ "
    if "í•˜ëŠ˜" in key: return "í•˜ëŠ˜ê³ "
    if "ì•„ë¼"  in key: return "ì•„ë¼ê³ "
    if "ë™ì‚°" in key: return "ë™ì‚°ê³ "
    return None

# ì—…ë¡œë“œëœ CSV íŒŒì¼ì„ í•™êµì— ë§¤í•‘(ìë™+ìˆ˜ë™)
def build_env_mapping(files):
    mapping_rows = []
    used = set()
    for i, f in enumerate(files or []):
        guess = infer_school_from_name(f.name)
        mapping_rows.append({"íŒŒì¼ëª…": f.name, "í•™êµ(ìë™ì¶”ë¡ )": guess, "ì„ íƒ": guess if guess else ""})
        if guess: used.add(guess)

    # ë¶€ì¡±/ì¤‘ë³µ ì•ˆë‚´
    return pd.DataFrame(mapping_rows)

env_map_df = build_env_mapping(env_files)

with st.sidebar:
    if env_files:
        st.divider()
        st.caption("ğŸ”— CSV â†’ í•™êµ ë§¤í•‘ (ìë™ ì¶”ë¡  ì‹¤íŒ¨ ì‹œ ì§ì ‘ ì„ íƒ)")
        # ê° íŒŒì¼ë³„ë¡œ ë§¤í•‘ ë“œë¡­ë‹¤ìš´ ì œê³µ
        if "env_selections" not in st.session_state:
            st.session_state.env_selections = {}

        for i, f in enumerate(env_files):
            default = env_map_df.loc[i, "ì„ íƒ"]
            st.session_state.env_selections[f.name] = st.selectbox(
                f"íŒŒì¼: {f.name}",
                [""] + SCHOOL_KEYS,
                index=([""] + SCHOOL_KEYS).index(default) if default in SCHOOL_KEYS else 0,
                key=f"sel_{f.name}"
            )

# --------------------------
# 2) ë°ì´í„° ë¡œë“œ(ì—…ë¡œë“œì—ì„œ ì½ê¸°) - ìºì‹œ
# --------------------------
@st.cache_data(show_spinner=True)
def load_data_from_uploads(_env_files_meta, _growth_bytes):
    """
    ì—…ë¡œë“œ íŒŒì¼ë“¤ë¡œë¶€í„° í™˜ê²½/ìƒìœ¡ í‰ê· ì„ ê³„ì‚°í•´ ë³‘í•© ë°ì´í„°í”„ë ˆì„ ë°˜í™˜.
    - _env_files_meta: [(school, bytes), ...] 4ê±´ ê¸°ëŒ€
    - _growth_bytes: ì—‘ì…€ íŒŒì¼ì˜ bytes (None í—ˆìš©)
    """
    # ===== í™˜ê²½ í‰ê·  =====
    env_rows = []
    for school, fbytes in _env_files_meta:
        # CSVë¥¼ íŒŒì¼ê°ì²´ë¡œ ë³€í™˜
        bio = io.BytesIO(fbytes)
        try:
            df = pd.read_csv(bio, encoding="utf-8")
        except Exception:
            bio.seek(0)
            df = pd.read_csv(bio, encoding="cp949")

        # ì¹¼ëŸ¼ ì •ê·œí™” (ì†Œë¬¸ì í‚¤ â†’ ì›ë˜ ì¹¼ëŸ¼ëª…)
        cols = {c.lower(): c for c in df.columns}
        need = ["temperature", "humid", "ec", "ph"]
        for n in need:
            if n not in cols:
                raise ValueError(f"[{school}] í™˜ê²½ CSV ì¹¼ëŸ¼ ëˆ„ë½: {n}")

        temperature = pd.to_numeric(df[cols["temperature"]], errors="coerce").dropna()
        humid       = pd.to_numeric(df[cols["humid"]], errors="coerce").dropna()
        ec_meas     = pd.to_numeric(df[cols["ec"]], errors="coerce").dropna()
        ph          = pd.to_numeric(df[cols["ph"]], errors="coerce").dropna()

        # pH ìŠ¤ì¼€ì¼ ë³´ì •: í‰ê· ì´ 100â†‘ë©´ /100
        if len(ph) and ph.mean() > 100:
            ph = ph / 100.0

        env_rows.append({
            "í•™êµ": school,
            "í‰ê·  ì˜¨ë„": temperature.mean() if len(temperature) else math.nan,
            "í‰ê·  ìŠµë„": humid.mean() if len(humid) else math.nan,
            "í‰ê·  EC(ì¸¡ì •)": ec_meas.mean() if len(ec_meas) else math.nan,
            "í‰ê·  pH": ph.mean() if len(ph) else math.nan,
        })
    env_df = pd.DataFrame(env_rows)

    # ===== ìƒìœ¡ í‰ê·  =====
    if _growth_bytes is None:
        raise ValueError("ìƒìœ¡ ì—‘ì…€(.xlsx)ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    g_bio = io.BytesIO(_growth_bytes)

    growth_rows = []
    for school in SCHOOL_KEYS:
        gdf = pd.read_excel(g_bio, sheet_name=school)
        g_bio.seek(0)  # ë‹¤ìŒ ì‹œíŠ¸ ì½ê¸°ë¥¼ ìœ„í•´ í¬ì¸í„° ë¦¬ì…‹

        if "ìƒì¤‘ëŸ‰(g)" in gdf.columns:
            # ì•„ë¼ê³  ì „ìš©(ì´ ìƒì¤‘ëŸ‰)
            avg_weight = pd.to_numeric(gdf["ìƒì¤‘ëŸ‰(g)"], errors="coerce").mean()
            avg_leaf   = math.nan
            avg_len    = math.nan
        else:
            # ë‹¤ë¥¸ í•™êµ: ì§€ìƒë¶€ ì¤‘ì‹¬ 3ì§€í‘œ
            need_cols = ["ì§€ìƒë¶€ ìƒì¤‘ëŸ‰(g)","ì§€ìƒë¶€ ê¸¸ì´(cm)","ì ìˆ˜(ì¥)"]
            for c in need_cols:
                if c not in gdf.columns:
                    raise ValueError(f"ìƒìœ¡ ì‹œíŠ¸[{school}] ì¹¼ëŸ¼ ëˆ„ë½: {c}")
            avg_weight = pd.to_numeric(gdf["ì§€ìƒë¶€ ìƒì¤‘ëŸ‰(g)"], errors="coerce").mean()
            avg_len    = pd.to_numeric(gdf["ì§€ìƒë¶€ ê¸¸ì´(cm)"], errors="coerce").mean()
            avg_leaf   = pd.to_numeric(gdf["ì ìˆ˜(ì¥)"], errors="coerce").mean()

        growth_rows.append({
            "í•™êµ": school,
            "í‰ê·  ì ìˆ˜": avg_leaf,
            "í‰ê·  ê¸¸ì´(cm)": avg_len,
            "í‰ê·  ìƒì¤‘ëŸ‰(g)": avg_weight
        })
    growth_df = pd.DataFrame(growth_rows)
    growth_df["EC(ì„¤ì •)"] = growth_df["í•™êµ"].map(EC_MAP)

    # ===== ë³‘í•© =====
    combined = pd.merge(growth_df, env_df, on="í•™êµ", how="left")
    combined["color"] = combined["í•™êµ"].map(COLOR_MAP)
    return combined

# ì—…ë¡œë“œê°€ ì™„ë£Œë˜ë©´ ë°”ì´íŠ¸ì™€ ë§¤í•‘ì„ ì¤€ë¹„
env_meta = []
if env_files:
    # ì‚¬ìš©ì ì„ íƒê°’ì—ì„œ í•™êµ ë§¤í•‘
    assigned = set()
    for f in env_files:
        school = st.session_state.env_selections.get(f.name) or infer_school_from_name(f.name)
        if not school:
            continue
        if school in assigned:
            st.warning(f"âš ï¸ {school}ì— ì¤‘ë³µ ë§¤í•‘ëœ CSVê°€ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
            continue
        env_meta.append((school, f.getvalue()))
        assigned.add(school)

# ë¡œë“œ ì‹œë„
combined_df = None
load_error = None
if env_meta and len(env_meta) >= 2 and growth_file is not None:
    try:
        combined_df = load_data_from_uploads(env_meta, growth_file.getvalue())
    except Exception as e:
        load_error = str(e)

# ìƒíƒœ ì•ˆë‚´
if not env_files or growth_file is None:
    st.info("â¬…ï¸ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ **í™˜ê²½ CSV(4ê°œ)** ì™€ **ìƒìœ¡ ì—‘ì…€(.xlsx)** ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. "
            "íŒŒì¼ëª…ì´ 'ì†¡ë„/í•˜ëŠ˜/ì•„ë¼/ë™ì‚°'ì„ í¬í•¨í•˜ë©´ ìë™ ë§¤í•‘ë©ë‹ˆë‹¤.")
elif load_error:
    st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {load_error}")
elif combined_df is None:
    st.warning("íŒŒì¼ì€ ì—…ë¡œë“œë˜ì—ˆì§€ë§Œ í•™êµ ë§¤í•‘ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê° CSVì— ëŒ€í•´ í•™êµë¥¼ ì„ íƒí•˜ì„¸ìš”.")
else:
    # ====================== ëŒ€ì‹œë³´ë“œ ë³¸ì²´ (ë°ì´í„° ì¡´ì¬) ======================
    # 3) ì‚¬ì´ë“œë°” í•„í„°
    with st.sidebar:
        st.divider()
        st.header("ğŸ”¬ ë°ì´í„° í•„í„°")
        school_options = ["ì „ì²´","ì†¡ë„ê³ (EC1)","í•˜ëŠ˜ê³ (EC2)","ì•„ë¼ê³ (EC4)","ë™ì‚°ê³ (EC8)"]
        sel_schools = st.multiselect("í•™êµ ì„ íƒ(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", school_options, default=["ì „ì²´"])

        env_options = ["ì˜¨ë„","ìŠµë„","EC","pH"]
        sel_env = st.multiselect("í™˜ê²½ ë³€ìˆ˜ ì„ íƒ", env_options, default=["ì˜¨ë„","ìŠµë„","EC"])

        metric_options = ["ì§€ìƒë¶€ ìƒì¤‘ëŸ‰","ì ìˆ˜","ì§€ìƒë¶€ ê¸¸ì´"]
        sel_metric = st.selectbox("ìƒìœ¡ ì§€í‘œ", metric_options, index=0)

    # í•™êµ í•„í„° ì ìš©
    def normalize_school_filter(selected):
        if ("ì „ì²´" in selected) or (not selected):
            return SCHOOL_KEYS
        mp = {"ì†¡ë„ê³ (EC1)":"ì†¡ë„ê³ ","í•˜ëŠ˜ê³ (EC2)":"í•˜ëŠ˜ê³ ","ì•„ë¼ê³ (EC4)":"ì•„ë¼ê³ ","ë™ì‚°ê³ (EC8)":"ë™ì‚°ê³ "}
        return [mp[s] for s in selected if s in mp]

    use_schools = normalize_school_filter(sel_schools)
    filtered = combined_df[combined_df["í•™êµ"].isin(use_schools)].copy()

    # 4) KPI
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ì´ í•™êµ ìˆ˜", f"{len(filtered):,}")

    overall_avg_w = filtered["í‰ê·  ìƒì¤‘ëŸ‰(g)"].mean()
    col2.metric("í‰ê·  ìƒì¤‘ëŸ‰", f"{overall_avg_w:.2f} g")

    best_row = filtered.loc[filtered["í‰ê·  ìƒì¤‘ëŸ‰(g)"].idxmax()]
    col3.metric("ìµœê³  EC ë†ë„ (ìƒì¤‘ëŸ‰ ê¸°ì¤€)", f"EC {int(best_row['EC(ì„¤ì •)'])}")

    col4.metric("ìµœê³  ìƒì¤‘ëŸ‰", f"{best_row['í‰ê·  ìƒì¤‘ëŸ‰(g)']:.2f} g")

    st.markdown("---")

    # 5) íƒ­
    tab1, tab2 = st.tabs(["ğŸ“Š ìƒìœ¡ ê²°ê³¼", "ğŸŒ¡ï¸ í™˜ê²½ ë¶„ì„"])

    # ê³µí†µ tidy
    def tidy_growth(df):
        return df[["í•™êµ","EC(ì„¤ì •)","í‰ê·  ìƒì¤‘ëŸ‰(g)","í‰ê·  ì ìˆ˜","í‰ê·  ê¸¸ì´(cm)","color"]].copy()

    growth_tidy = tidy_growth(filtered)

    # --------------------------
    # íƒ­1: ìƒìœ¡ ê²°ê³¼
    # --------------------------
    with tab1:
        metric_col_map = {
            "ì§€ìƒë¶€ ìƒì¤‘ëŸ‰": "í‰ê·  ìƒì¤‘ëŸ‰(g)",
            "ì ìˆ˜": "í‰ê·  ì ìˆ˜",
            "ì§€ìƒë¶€ ê¸¸ì´": "í‰ê·  ê¸¸ì´(cm)"
        }
        y_col = metric_col_map[sel_metric]

        ec_order = [1,2,4,8]
        line_df = growth_tidy.sort_values("EC(ì„¤ì •)").dropna(subset=[y_col])

        # ìµœê³ ì  í‘œì‹œ í”Œë˜ê·¸
        if not line_df.empty:
            max_idx = line_df[y_col].idxmax()
            line_df["is_max"] = line_df.index == max_idx
        else:
            line_df["is_max"] = False

        line = alt.Chart(line_df).mark_line(point=True, strokeWidth=2, color="#6aa9ff").encode(
            x=alt.X("EC(ì„¤ì •):O", sort=ec_order, title="EC (ì„¤ì •)"),
            y=alt.Y(f"{y_col}:Q", title=sel_metric)
        )
        star = alt.Chart(line_df[line_df["is_max"]]).mark_point(shape="star", size=200, color="#ef4444").encode(
            x=alt.X("EC(ì„¤ì •):O", sort=ec_order),
            y=alt.Y(f"{y_col}:Q")
        )

        st.caption("**ì°¨íŠ¸ 1. EC vs ì„ íƒ ì§€í‘œ (êº¾ì€ì„ , ìµœê³ ê°’ â˜… í‘œì‹œ)**")
        st.altair_chart((line + star).properties(height=340), use_container_width=True)

        # í•™êµë³„ TOP 4 (ê°€ë¡œ ë§‰ëŒ€)
        bar_df = growth_tidy[["í•™êµ","color",y_col]].dropna().sort_values(y_col, ascending=False)
        bar = alt.Chart(bar_df).mark_bar().encode(
            x=alt.X(f"{y_col}:Q", title=sel_metric),
            y=alt.Y("í•™êµ:N", sort="-x", title=None),
            color=alt.Color("í•™êµ:N",
                            scale=alt.Scale(range=[combined_df[combined_df['í•™êµ']=='ì†¡ë„ê³ ']['color'].iloc[0],
                                                   combined_df[combined_df['í•™êµ']=='í•˜ëŠ˜ê³ ']['color'].iloc[0],
                                                   combined_df[combined_df['í•™êµ']=='ì•„ë¼ê³ ']['color'].iloc[0],
                                                   combined_df[combined_df['í•™êµ']=='ë™ì‚°ê³ ']['color'].iloc[0]]),
                            legend=None)
        )
        text = bar.mark_text(align='left', dx=5, color="#334155").encode(
            text=alt.Text(f"{y_col}:Q", format=".2f")
        )

        st.caption("**ì°¨íŠ¸ 2. í•™êµë³„ TOP 4 (ì„ íƒ ì§€í‘œ ë‚´ë¦¼ì°¨ìˆœ, ë§‰ëŒ€ ë ê°’ í‘œì‹œ)**")
        st.altair_chart((bar + text).properties(height=340), use_container_width=True)

        # 3ì§€í‘œ ì •ê·œí™”(0-100)
        norm_cols = ["í‰ê·  ìƒì¤‘ëŸ‰(g)","í‰ê·  ì ìˆ˜","í‰ê·  ê¸¸ì´(cm)"]
        norm_df = growth_tidy[["í•™êµ","color"] + norm_cols].copy()
        for c in norm_cols:
            cmax = norm_df[c].max(skipna=True)
            norm_df[c+"_ì ìˆ˜"] = (norm_df[c] / cmax * 100).where(pd.notna(norm_df[c]), None)

        tidy_norm = norm_df.melt(id_vars=["í•™êµ","color"], value_vars=[c+"_ì ìˆ˜" for c in norm_cols],
                                 var_name="ì§€í‘œ", value_name="ì ìˆ˜")
        tidy_norm["ì§€í‘œ"] = tidy_norm["ì§€í‘œ"].replace({
            "í‰ê·  ìƒì¤‘ëŸ‰(g)_ì ìˆ˜":"ìƒì¤‘ëŸ‰ ì ìˆ˜",
            "í‰ê·  ì ìˆ˜_ì ìˆ˜":"ì ìˆ˜ ì ìˆ˜",
            "í‰ê·  ê¸¸ì´(cm)_ì ìˆ˜":"ê¸¸ì´ ì ìˆ˜",
        })

        grouped = alt.Chart(tidy_norm.dropna()).mark_bar().encode(
            x=alt.X("í•™êµ:N", title=None),
            y=alt.Y("ì ìˆ˜:Q", title="ì •ê·œí™” ì ìˆ˜(0-100)"),
            color=alt.Color("ì§€í‘œ:N", scale=alt.Scale(range=["#9ec5fe","#a7f3d0","#fde68a"])),
            column=alt.Column("ì§€í‘œ:N", header=alt.Header(labelOrient="bottom"))
        ).resolve_scale(y='independent')

        st.caption("**ì°¨íŠ¸ 3. 3ê°€ì§€ ì§€í‘œ ì¢…í•© (0-100 ì •ê·œí™”, ê·¸ë£¹ ë§‰ëŒ€)**")
        st.altair_chart(grouped.properties(height=320), use_container_width=True)

    # --------------------------
    # íƒ­2: í™˜ê²½ ë¶„ì„
    # --------------------------
    with tab2:
        env_map = {"ì˜¨ë„":"í‰ê·  ì˜¨ë„","ìŠµë„":"í‰ê·  ìŠµë„","EC":"í‰ê·  EC(ì¸¡ì •)","pH":"í‰ê·  pH"}
        env_use_cols = [env_map[e] for e in ["ì˜¨ë„","ìŠµë„","EC","pH"] if e in (sel_env or [])]
        if not env_use_cols:
            st.info("í™˜ê²½ ë³€ìˆ˜ë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        else:
            env_df = filtered[["í•™êµ","color"] + env_use_cols].copy()
            tidy_env = env_df.melt(id_vars=["í•™êµ","color"], var_name="ë³€ìˆ˜", value_name="ê°’")

            chart4 = alt.Chart(tidy_env.dropna()).mark_bar().encode(
                x=alt.X("í•™êµ:N", title=None),
                y=alt.Y("ê°’:Q", title="í™˜ê²½ ê°’"),
                color=alt.Color("í•™êµ:N",
                                scale=alt.Scale(range=[combined_df[combined_df['í•™êµ']=='ì†¡ë„ê³ ']['color'].iloc[0],
                                                       combined_df[combined_df['í•™êµ']=='í•˜ëŠ˜ê³ ']['color'].iloc[0],
                                                       combined_df[combined_df['í•™êµ']=='ì•„ë¼ê³ ']['color'].iloc[0],
                                                       combined_df[combined_df['í•™êµ']=='ë™ì‚°ê³ ']['color'].iloc[0]]),
                                legend=None),
                column=alt.Column("ë³€ìˆ˜:N", header=alt.Header(labelOrient="bottom"))
            ).resolve_scale(y='independent')

            st.caption("**ì°¨íŠ¸ 4. í•™êµë³„ í™˜ê²½ ì¡°ê±´ (ì„ íƒ ë³€ìˆ˜, ê·¸ë£¹ ë§‰ëŒ€)**")
            st.altair_chart(chart4.properties(height=320), use_container_width=True)

        # ìŠ¤í”¼ì–´ë§Œ |r| (í•™êµ ìˆ˜ 2ê°œ ë¯¸ë§Œì´ë©´ ë¶ˆê°€)
        def spearman_abs(x, y):
            sx = pd.Series(x).rank()
            sy = pd.Series(y).rank()
            return abs(sx.corr(sy))

        rank_rows = []
        if len(filtered) >= 2:
            y = filtered["í‰ê·  ìƒì¤‘ëŸ‰(g)"]
            for label, col in env_map.items():
                if col in filtered.columns:
                    r = spearman_abs(filtered[col], y)
                    rank_rows.append([label, r])

        rank_df = pd.DataFrame(rank_rows, columns=["í™˜ê²½ ìš”ì¸","|Spearman r|"]).sort_values("|Spearman r|", ascending=False)
        if rank_df.empty:
            st.info("í™˜ê²½ ìš”ì¸ ì˜í–¥ë ¥ ìˆœìœ„ë¥¼ ê³„ì‚°í•˜ë ¤ë©´ 2ê°œ ì´ìƒì˜ í•™êµë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        else:
            rank_df["ì˜í–¥ë ¥ ì ìˆ˜(0-100)"] = (rank_df["|Spearman r|"] * 100).round(0).astype(int)
            base = alt.Chart(rank_df).mark_bar().encode(
                x=alt.X("ì˜í–¥ë ¥ ì ìˆ˜(0-100):Q", title="ì˜í–¥ë ¥ ì ìˆ˜(0-100)", scale=alt.Scale(domain=[0,100])),
                y=alt.Y("í™˜ê²½ ìš”ì¸:N", sort="-x", title=None),
                color=alt.condition(
                    alt.datum["ì˜í–¥ë ¥ ì ìˆ˜(0-100)"] == rank_df["ì˜í–¥ë ¥ ì ìˆ˜(0-100)"].max(),
                    alt.value("#a78bfa"),  # 1ìœ„ ê°•ì¡°
                    alt.value("#475569")
                )
            )
            txt = base.mark_text(align="left", dx=6, color="#cbd5e1").encode(
                text=alt.Text("ì˜í–¥ë ¥ ì ìˆ˜(0-100):Q", format=".0f")
            )
            st.caption("**ì°¨íŠ¸ 5. í™˜ê²½ ìš”ì¸ ì˜í–¥ë ¥ ìˆœìœ„ (ìŠ¤í”¼ì–´ë§Œ ìƒê´€ ì ˆëŒ“ê°’, n=4 ì°¸ê³ ìš©)**")
            st.altair_chart((base + txt).properties(height=320), use_container_width=True)

    # ì‚¬ìš© ì•ˆë‚´
    with st.expander("â„¹ï¸ ì‚¬ìš©ë²• / ì—…ë¡œë“œ íŒ"):
        st.markdown(
            """
            **ì—…ë¡œë“œ íŒ**
            - í™˜ê²½ CSVëŠ” íŒŒì¼ëª…ì— `ì†¡ë„/í•˜ëŠ˜/ì•„ë¼/ë™ì‚°`ì´ ë“¤ì–´ê°€ë©´ ìë™ ë§¤í•‘ë©ë‹ˆë‹¤. ì•„ë‹ˆë¼ë©´ ì‚¬ì´ë“œë°”ì—ì„œ ì§ì ‘ ë§¤í•‘í•˜ì„¸ìš”.
            - pHê°€ 500ëŒ€ì²˜ëŸ¼ ë¹„ì •ìƒ ìŠ¤ì¼€ì¼ì´ë©´ ìë™ìœ¼ë¡œ `/100` ë³´ì •ë©ë‹ˆë‹¤.

            **ì£¼ì˜**
            - í™˜ê²½ ì˜í–¥ë ¥ ìˆœìœ„ëŠ” í‘œë³¸(n=4)ì´ ì‘ì•„ **ì°¸ê³ ìš©**ì…ë‹ˆë‹¤.
            - ì•„ë¼ê³ ëŠ” â€˜ìƒì¤‘ëŸ‰(g)â€™ ë‹¨ì¼ ì¹¼ëŸ¼ì´ë¯€ë¡œ ì ìˆ˜/ê¸¸ì´ í‰ê· ì€ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            """
        )
