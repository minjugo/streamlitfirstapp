from __future__ import annotations  # â† ë§¨ ì²« ì¤„ì— ë‘ì„¸ìš” (íƒ€ì…íŒíŠ¸ ì§€ì—°í‰ê°€ë¡œ NameError ë°©ì§€)

import unicodedata
from pathlib import Path
from datetime import datetime

import pandas as pd
import numpy as np
import altair as alt

try:
    import streamlit as st            # â† ë°˜ë“œì‹œ í•„ìš”
except Exception as e:
    raise RuntimeError("Streamlit import ì‹¤íŒ¨. requirements.txtì— streamlitì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.") from e


# ---------- (1) ê²¬ê³ í•œ íŒŒì¼ íƒìƒ‰ê¸° ----------
def resolve_file(preferred_name: str, patterns: list[str]) -> Path:
    """
    - preferred_name: ê¸°ëŒ€ íŒŒì¼ëª…(ì˜ˆ: 'ì†¡ë„ê³  í™˜ê²½ë°ì´í„° í†µí•©.csv')
    - patterns: ëŒ€ì•ˆ íŒ¨í„´ë“¤(ì˜ˆ: ['*í™˜ê²½ë°ì´í„°*í†µí•©*.csv'])
    í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ í´ë”ì—ì„œ ìœ ë‹ˆì½”ë“œ ì •ê·œí™”(NFC) ì ìš© í›„ íƒìƒ‰.
    """
    base = Path(__file__).parent.resolve()

    # 1) ìš°ì„  ì •í™• ì¼ì¹˜ ì‹œë„ (NFCë¡œ ì •ê·œí™”)
    pref_nfc = unicodedata.normalize("NFC", preferred_name)
    p = base / pref_nfc
    if p.exists():
        return p

    # 2) í´ë” ë‚´ íŒŒì¼ëª…ì„ ëª¨ë‘ ì •ê·œí™”í•´ ì¼ì¹˜ í™•ì¸
    for child in base.iterdir():
        if child.is_file():
            name_nfc = unicodedata.normalize("NFC", child.name)
            if name_nfc == pref_nfc:
                return child

    # 3) íŒ¨í„´ íƒìƒ‰(ì—¬ëŸ¬ í›„ë³´)
    for pat in patterns:
        for hit in base.glob(pat):
            return hit  # ì²« ë²ˆì§¸ ë§¤ì¹˜

    # 4) ëª» ì°¾ìœ¼ë©´ í´ë” ëª©ë¡ ë³´ì—¬ì£¼ë©° ì—ëŸ¬
    all_files = [unicodedata.normalize("NFC", c.name) for c in base.iterdir() if c.is_file()]
    raise FileNotFoundError(
        f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{preferred_name}'\n"
        f"ê²€ìƒ‰ í´ë”: {base}\n"
        f"íŒ¨í„´: {patterns}\n"
        f"í˜„ì¬ í´ë” íŒŒì¼: {all_files}"
    )

# ---------- (2) ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤ ----------
ENV_FILE = resolve_file(
    "ì†¡ë„ê³  í™˜ê²½ë°ì´í„° í†µí•©.csv",
    patterns=["*í™˜ê²½*í†µí•©*.csv", "*í™˜ê²½ë°ì´í„°*í†µí•©*.csv", "*í™˜ê²½ë°ì´í„°*.csv"]
)
GROW_FILE = resolve_file(
    "ì†¡ë„ê³  ìŠ¤ë§ˆíŠ¸íŒœ ìƒìœ¡ ê²°ê³¼.csv",
    patterns=["*ìŠ¤ë§ˆíŠ¸íŒœ*ìƒìœ¡*ê²°ê³¼*.csv", "*ìƒìœ¡*ê²°ê³¼*.csv", "*ìŠ¤ë§ˆíŠ¸íŒœ*.csv"]
)

UNITS = {"temp":"â„ƒ","humid":"%","co2":"ppm","ec":"dS/m","ph":"","wt":"â„ƒ",
         "length":"cm","wet_weight":"g","dry_weight":"g"}

# -------------------------------------------------
# ìœ í‹¸
# -------------------------------------------------
def fmt_num(x): 
    return "-" if pd.isna(x) else f"{x:,.2f}"

def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # ì—´ ì´ë¦„ í†µì¼
    mapping = {
        "ì¸¡ì •ì¼ì‹œ":"date","ì¼ì‹œ":"date","ë‚ ì§œ":"date","date":"date",
        "ì˜¨ë„(â„ƒ)":"temp","ì˜¨ë„":"temp","temp":"temp","tmep":"temp",
        "ìŠµë„(%)":"humid","ìŠµë„":"humid","humidity":"humid","humid":"humid",
        "coâ‚‚(ppm)":"co2","co2(ppm)":"co2","co2":"co2","coâ‚‚":"co2",
        "ec(ds/m)":"ec","ec":"ec", "pH":"ph","ph":"ph",
        "ìˆ˜ì˜¨(â„ƒ)":"wt","ìˆ˜ì˜¨":"wt","w.t":"wt","water_temp":"wt","wt":"wt",
        "ì§€ìƒë¶€ ê¸¸ì´(cm)":"length","ìƒìœ¡ê¸¸ì´(cm)":"length","ê¸¸ì´(cm)":"length","length":"length",
        "ì ìˆ˜(ì¥)":"leaves","ììˆ˜(ê°œ)":"leaves","leaves":"leaves",
        "ì§€ìƒë¶€ ìƒì¤‘ëŸ‰(g)":"wet_weight","ìƒì¤‘ëŸ‰(g)":"wet_weight","wet_weight":"wet_weight",
        "ì§€ìƒë¶€ ê±´ì¤‘ëŸ‰(g)":"dry_weight","ê±´ì¤‘ëŸ‰(g)":"dry_weight","dry_weight":"dry_weight",
    }
    new_cols = []
    for c in df.columns:
        key = c.strip()
        low = key.lower()
        if key in mapping: new_cols.append(mapping[key]); continue
        if low in mapping: new_cols.append(mapping[low]); continue
        # íœ´ë¦¬ìŠ¤í‹±
        if any(k in low for k in ["ì˜¨ë„","temp","tmep"]): new_cols.append("temp")
        elif any(k in low for k in ["ìŠµë„","humid"]): new_cols.append("humid")
        elif "co2" in low or "coâ‚‚" in key.lower(): new_cols.append("co2")
        elif low.startswith("ec"): new_cols.append("ec")
        elif low == "ph": new_cols.append("ph")
        elif any(k in low for k in ["ìˆ˜ì˜¨","water","w.t","wt"]): new_cols.append("wt")
        elif any(k in low for k in ["ììˆ˜","ì ìˆ˜","leaves"]): new_cols.append("leaves")
        elif any(k in low for k in ["ìƒìœ¡ê¸¸ì´","ì§€ìƒë¶€ ê¸¸ì´","length"]): new_cols.append("length")
        elif any(k in low for k in ["ìƒì¤‘ëŸ‰","wet_weight"]): new_cols.append("wet_weight")
        elif any(k in low for k in ["ê±´ì¤‘ëŸ‰","dry_weight"]): new_cols.append("dry_weight")
        elif any(k in low for k in ["ì¸¡ì •ì¼ì‹œ","ì¼ì‹œ","ë‚ ì§œ","date"]): new_cols.append("date")
        else: new_cols.append(c)
    df.columns = new_cols
    return df

def parse_env_csv(path: str) -> pd.DataFrame:
    """
    ì†¡ë„ê³  í™˜ê²½ë°ì´í„° í†µí•©.csv ì „ìš© íŒŒì„œ (cp949)
    ì›ë³¸ì€ co2/ec-ph-wt/humid/tempê°€ ì„œë¡œ ë‹¤ë¥¸ 'ë‚ ì§œ/ì‹œê°„' ì—´ì— ë“¤ì–´ìˆìœ¼ë¯€ë¡œ
    ê° ë³€ìˆ˜ë³„ë¡œ datetimeì„ ë§Œë“¤ê³  íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ outer-join.
    """
    raw = pd.read_csv(path, encoding="cp949")
    # ì›ë³¸ ì—´ ì˜ˆì‹œ: ['ë‚ ì§œ','ì‹œê°„','co2','ë‚ ì§œ.1','ì‹œê°„.1','ec','ph','w.t','ë‚ ì§œ.2','ì‹œê°„.2','humid','ë‚ ì§œ.3','ì‹œê°„.3','temp']
    var_map = {
        "co2":   ("ë‚ ì§œ","ì‹œê°„","co2"),
        "ec":    ("ë‚ ì§œ.1","ì‹œê°„.1","ec"),
        "ph":    ("ë‚ ì§œ.1","ì‹œê°„.1","ph"),
        "wt":    ("ë‚ ì§œ.1","ì‹œê°„.1","w.t"),
        "humid": ("ë‚ ì§œ.2","ì‹œê°„.2","humid"),
        "temp":  ("ë‚ ì§œ.3","ì‹œê°„.3","temp"),
    }
    frames = []
    for var, (dc, tc, vc) in var_map.items():
        if dc in raw.columns and tc in raw.columns and vc in raw.columns:
            df = raw[[dc, tc, vc]].copy()
            df["date"] = pd.to_datetime(df[dc].astype(str).str.strip() + " " + df[tc].astype(str).str.strip(), errors="coerce")
            df = df.drop(columns=[dc, tc]).rename(columns={vc: var})
            df = df[~df["date"].isna()]
            frames.append(df.set_index("date"))
    if not frames:
        # fallback: ì „ì²´ì—ì„œ ë‚ ì§œ ë¹„ìŠ·í•œ ì»¬ëŸ¼ ì°¾ì•„ date ìƒì„±
        raw = standardize_columns(raw)
        if "date" not in raw.columns:
            raw["date"] = pd.to_datetime(raw.iloc[:,0], errors="coerce")
        return raw
    env = pd.concat(frames, axis=1).sort_index().reset_index()
    return env

def load_growth_csv(path: str) -> pd.DataFrame:
    df = pd.read_csv(path, encoding="cp949")
    df = df.loc[:, ~df.columns.str.contains("^Unnamed")]
    df = standardize_columns(df)
    # ìˆ«ìí˜• ë³€í™˜
    for c in ["length","leaves","wet_weight","dry_weight"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    # ëŒ€ë¶€ë¶„ ë‚ ì§œê°€ ì—†ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return df

def numeric_summary(df, cols):
    if not cols: return pd.DataFrame({"column":[],"mean":[],"min":[],"max":[]})
    out = df[cols].agg(["mean","min","max"]).T.reset_index()
    out.columns = ["column","mean","min","max"]
    return out

def corr_env_vs_growth(env_df: pd.DataFrame, grow_df: pd.DataFrame, env_cols, grow_cols):
    # dateê°€ ë‘˜ ë‹¤ ìˆì–´ì•¼ ì˜ë¯¸ ìˆê²Œ ë§¤ì¹­ ê°€ëŠ¥
    if "date" in env_df.columns and "date" in grow_df.columns:
        merged = pd.merge(env_df[["date"]+env_cols], grow_df[["date"]+grow_cols], on="date", how="inner")
    else:
        # ë‚ ì§œ ë§¤ì¹­ ë¶ˆê°€ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ì •ì§í•˜ê²Œ ë¹„í™œì„±í™”)
        return pd.DataFrame(columns=["env","grow","corr"])
    pairs = []
    for e in env_cols:
        for g in grow_cols:
            s = merged[[e,g]].dropna()
            if len(s) >= 3:
                pairs.append({"env":e,"grow":g,"corr":s[e].corr(s[g])})
    return pd.DataFrame(pairs)

def altair_heatmap(corr_df: pd.DataFrame):
    if corr_df.empty:
        return alt.Chart(pd.DataFrame({"msg":["ìƒê´€ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]})).mark_text().encode(text="msg")
    corr_df = corr_df.copy()
    corr_df["corr_label"] = corr_df["corr"].round(2).astype(str)
    base = alt.Chart(corr_df).mark_rect().encode(
        x=alt.X("env:N", title="í™˜ê²½ ë³€ìˆ˜"),
        y=alt.Y("grow:N", title="ìƒìœ¡ ì§€í‘œ"),
        color=alt.Color("corr:Q", scale=alt.Scale(scheme="redblue", domain=(-1,1))),
        tooltip=[alt.Tooltip("env:N"), alt.Tooltip("grow:N"), alt.Tooltip("corr:Q", format=".3f")]
    ).properties(title="í™˜ê²½â€“ìƒìœ¡ ìƒê´€ê³„ìˆ˜ Heatmap", height=300)
    text = alt.Chart(corr_df).mark_text(baseline="middle").encode(x="env:N", y="grow:N", text="corr_label:N")
    return base + text

def scatter_grid(df, env_cols, grow_cols):
    charts = []
    for e in env_cols:
        for g in grow_cols:
            s = df[[e,g]].dropna()
            if len(s) < 3: continue
            c = alt.Chart(s).mark_circle(opacity=0.5).encode(
                x=alt.X(f"{e}:Q", title=f"{e} ({UNITS.get(e,'')})"),
                y=alt.Y(f"{g}:Q", title=f"{g} ({UNITS.get(g,'')})"),
                tooltip=[alt.Tooltip(f"{e}:Q", format=",.2f"), alt.Tooltip(f"{g}:Q", format=",.2f")]
            ).properties(width=300, height=240)
            charts.append(c + c.transform_regression(e, g).mark_line())
    if not charts:
        return alt.Chart(pd.DataFrame({"msg":["í‘œì‹œí•  ì‚°ì ë„ê°€ ì—†ìŠµë‹ˆë‹¤."]})).mark_text().encode(text="msg")
    row = None; rows = []
    for i, ch in enumerate(charts):
        row = ch if i % 3 == 0 else row | ch
        if i % 3 == 2: rows.append(row)
    if row is not None and (len(charts) % 3 != 0): rows.append(row)
    out = rows[0]
    for r in rows[1:]: out = out & r
    return out.properties(title="í™˜ê²½ìš”ì†Œë³„ ìƒìœ¡ ì˜í–¥ë„")

# -------------------------------------------------
# ë°ì´í„° ë¡œë“œ
# -------------------------------------------------
with st.expander("ğŸ“¥ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ìš”ì•½", expanded=True):
    # í™˜ê²½ CSV
    try:
        env_df = parse_env_csv(ENV_FILE)
        st.success(f"í™˜ê²½ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {ENV_FILE} (shape={env_df.shape})")
    except Exception as e:
        st.error(f"í™˜ê²½ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        st.stop()

    # ìƒìœ¡ CSV
    try:
        grow_df = load_growth_csv(GROW_FILE)
        st.success(f"ìƒìœ¡ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {GROW_FILE} (shape={grow_df.shape})")
    except Exception as e:
        st.warning(f"ìƒìœ¡ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨(ì„ íƒì‚¬í•­): {e}")
        grow_df = pd.DataFrame()

    # í‘œì¤€í™”
    env_df = standardize_columns(env_df)
    if "date" in env_df.columns:
        env_df["date"] = pd.to_datetime(env_df["date"], errors="coerce")

    # ë¯¸ë¦¬ë³´ê¸°
    st.subheader("í™˜ê²½ ë°ì´í„° ì²˜ìŒ 10í–‰")
    st.dataframe(env_df.head(10), use_container_width=True)

    if not grow_df.empty:
        st.subheader("ìƒìœ¡ ë°ì´í„° ì²˜ìŒ 10í–‰")
        st.dataframe(grow_df.head(10), use_container_width=True)

    # íƒ€ì…/ê²°ì¸¡ ë¦¬í¬íŠ¸
    def report(df):
        rows = []
        for c in df.columns:
            miss = df[c].isna().mean()*100 if len(df) else 0
            # ìˆ«ìí˜• ê°€ëŠ¥ì„±
            can_num = df[c].dtype.kind in "biufc"
            if not can_num:
                try:
                    pd.to_numeric(df[c], errors="raise"); can_num=True
                except: pass
            rows.append({"column":c,"dtype":str(df[c].dtype),"missing_ratio(%)":round(miss,2),"numeric_candidate":can_num})
        return pd.DataFrame(rows)

    st.subheader("í™˜ê²½ ë°ì´í„° íƒ€ì… & ê²°ì¸¡ ë¹„ìœ¨")
    st.dataframe(report(env_df), use_container_width=True)
    if not grow_df.empty:
        st.subheader("ìƒìœ¡ ë°ì´í„° íƒ€ì… & ê²°ì¸¡ ë¹„ìœ¨")
        st.dataframe(report(grow_df), use_container_width=True)

    st.subheader("ìˆ«ìí˜• ìš”ì•½ (í‰ê· /ìµœì†Ÿê°’/ìµœëŒ“ê°’)")
    env_num = [c for c in ["temp","humid","co2","ec","ph","wt"] if c in env_df.columns]
    env_sum = numeric_summary(env_df, env_num)
    st.write("í™˜ê²½:", env_sum)

    if not grow_df.empty:
        grow_num = [c for c in ["length","wet_weight","dry_weight","leaves"] if c in grow_df.columns]
        grow_sum = numeric_summary(grow_df, grow_num)
        st.write("ìƒìœ¡:", grow_sum)

# -------------------------------------------------
# ì‚¬ì´ë“œë°” í•„í„° (í™˜ê²½ ë°ì´í„° ê¸°ì¤€)
# -------------------------------------------------
st.sidebar.header("ğŸ” ë°ì´í„° í•„í„°")
if "date" in env_df.columns and env_df["date"].notna().any():
    min_date = env_df["date"].min()
    max_date = env_df["date"].max()
    start, end = st.sidebar.date_input(
        "ë‚ ì§œ ë²”ìœ„ ì„ íƒ (í™˜ê²½ ë°ì´í„° ê¸°ì¤€)",
        (min_date.date(), max_date.date()) if pd.notna(min_date) else (datetime.today().date(), datetime.today().date()),
    )
    mask = (env_df["date"] >= pd.to_datetime(start)) & (env_df["date"] <= pd.to_datetime(end) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1))
    env_f = env_df.loc[mask].copy()
else:
    st.sidebar.info("í™˜ê²½ ë°ì´í„°ì— dateê°€ ì—†ì–´ ì „ì²´ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    env_f = env_df.copy()

# ë‹¤ìš´ë¡œë“œ (cp949)
csv_bytes = env_f.to_csv(index=False, encoding="cp949").encode("cp949", errors="ignore")
st.sidebar.download_button("â¬‡ï¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV, cp949)", data=csv_bytes, file_name="filtered_env.csv", mime="text/csv")
st.sidebar.markdown("---")
st.sidebar.caption("**ë°ì´í„° ì¶œì²˜:** ì†¡ë„ê³ ë“±í•™êµ ìŠ¤ë§ˆíŠ¸íŒœ í”„ë¡œì íŠ¸(2025, ê·¹ì§€ì—°êµ¬ì†Œ Ã— ì¸ì²œêµìœ¡ì²­)")

# -------------------------------------------------
# í•µì‹¬ ë©”íŠ¸ë¦­ (í™˜ê²½ + ìƒìœ¡í‰ê· )
# -------------------------------------------------
st.markdown("### ğŸ“Œ í•µì‹¬ ë©”íŠ¸ë¦­")
def avg(col, df): 
    return pd.to_numeric(df[col], errors="coerce").mean() if col in df.columns else np.nan

m1,m2,m3,m4 = st.columns(4)
m1.metric("í‰ê·  ì˜¨ë„ (â„ƒ)", fmt_num(avg("temp", env_f)))
m2.metric("í‰ê·  ìŠµë„ (%)", fmt_num(avg("humid", env_f)))
m3.metric("í‰ê·  COâ‚‚ (ppm)", fmt_num(avg("co2", env_f)))
m4.metric("í‰ê·  EC (dS/m)", fmt_num(avg("ec", env_f)))
m5,m6,m7,_ = st.columns(4)
m5.metric("í‰ê·  pH", fmt_num(avg("ph", env_f)))
m6.metric("í‰ê·  ìƒìœ¡ê¸¸ì´ (cm)", fmt_num(avg("length", grow_df) if not grow_df.empty else np.nan))
m7.metric("í‰ê·  ìƒì¤‘ëŸ‰ (g)", fmt_num(avg("wet_weight", grow_df) if not grow_df.empty else np.nan))

# -------------------------------------------------
# ìƒê´€ë¶„ì„ (í™˜ê²½â†”ìƒìœ¡) â€“ ë‚ ì§œ ë§¤ì¹­ ìˆì„ ë•Œë§Œ
# -------------------------------------------------
st.markdown("### ğŸ”— í™˜ê²½â€“ìƒìœ¡ ìƒê´€ ë¶„ì„")
env_cols_sel = [c for c in ["temp","humid","co2","ec","ph","wt"] if c in env_f.columns]
grow_cols_sel = [c for c in ["length","wet_weight","dry_weight"] if not grow_df.empty and c in grow_df.columns]

corr_df = corr_env_vs_growth(env_f, grow_df, env_cols_sel, grow_cols_sel) if grow_cols_sel else pd.DataFrame(columns=["env","grow","corr"])

c1, c2 = st.columns([2,1])
with c1:
    st.altair_chart(altair_heatmap(corr_df), use_container_width=True)
with c2:
    if corr_df.empty:
        st.info("ìƒìœ¡ ë°ì´í„°ì— ë‚ ì§œ ì •ë³´ê°€ ì—†ê±°ë‚˜ ë§¤ì¹­ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ìƒê´€ ë¶„ì„ì„ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        top5 = corr_df.assign(abs_corr=corr_df["corr"].abs()).sort_values("abs_corr", ascending=False).head(5)
        st.markdown("**ìƒê´€ ìƒìœ„ 5ê°œ (ì ˆëŒ€ê°’ ê¸°ì¤€)**")
        st.dataframe(top5[["env","grow","corr"]].round(3), use_container_width=True)

# -------------------------------------------------
# í™˜ê²½ìš”ì†Œë³„ ìƒìœ¡ ì˜í–¥ë„ (ë‚ ì§œ ë§¤ì¹­ ì‹œ ì‚°ì ë„)
# -------------------------------------------------
st.markdown("### ğŸ“ˆ í™˜ê²½ìš”ì†Œë³„ ìƒìœ¡ ì˜í–¥ë„")
if not corr_df.empty:
    # ë§¤ì¹­ëœ ë°ì´í„°ë¡œë§Œ ì‚°ì ë„ êµ¬ì„±
    merged_for_plot = pd.merge(env_f[["date"]+env_cols_sel], grow_df[["date"]+grow_cols_sel], on="date", how="inner").dropna()
    st.altair_chart(scatter_grid(merged_for_plot, env_cols_sel, grow_cols_sel), use_container_width=True)
else:
    st.info("ë‚ ì§œê°€ ë§¤ì¹­ë˜ëŠ” í™˜ê²½â€“ìƒìœ¡ ë°ì´í„°ê°€ ì—†ì–´ ì‚°ì ë„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

st.markdown("---")
st.caption("Made by ì†¡ë„ê³  EcoSmartFarm Team, with AI support")
